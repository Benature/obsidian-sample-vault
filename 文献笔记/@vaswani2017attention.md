---
aliases:
  - Transformer
tags:
  - CCF/A/NeurIPS
year: 2017
title: Attention is all you need
container: Adv. Neural Inf. Process. Syst.
url: 
zotero: zotero://select/items/@vaswani2017attention
authors:
  - "[[Ashish Vaswani]]"
  - "[[Noam Shazeer]]"
  - "[[Niki Parmar]]"
  - "[[Jakob Uszkoreit]]"
  - "[[Llion Jones]]"
  - "[[Aidan N Gomez]]"
  - "[[Åukasz Kaiser]]"
  - "[[Illia Polosukhin]]"
github: https://github.com/hyunwoongko/transformer
---
- [ ] ã€ŠAttention is all you needã€‹[ğŸ†‰](zotero://select/items/@vaswani2017attention) ^read

related:: [[ChatGPT]], [[AI]]
affiliation:: 

---

- abbr.

#### comment

## 0 abstract

## 1 Intro


## 2 Background

æ™®é€šé»è´´ï¼š

â€œSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.â€ (Vaswani et al., 2017, p. 2) ^sample-raw


Text Format è‡ªå®šä¹‰é»è´´ç»“æœï¼š

Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. [ğŸ”–](zotero://open-pdf/library/items/NI67YQF6?page=2&annotation=WUFVWDU8) ^sample-format
