---
beginDate: 2024-05-13
tags:
  - timeline
wiki: https://zh.wikipedia.org/wiki/GPT-4o
company: "[[OpenAI]]"
---
GPT-4o 在语音、多语言和视觉基准测试中取得了最先进的成果，在音频语音识别和翻译领域创下了新纪录。 GPT-4o 在 MMLU 基准测试中的得分为 88.7，而 [[GPT-4]] 的得分为 86.5。 

根据该公司的演示，GPT-4o 将有效地将 ChatGPT 转变为可以进行实时语音对话的数字个人助理。它还能够使用文本和“视觉”进行交互，这意味着它可以查看用户上传的屏幕截图、照片、文档或图表，并就它们进行对话。OpenAI 演示了与 ChatGPT 的语音对话，以获得解决数学问题的实时说明、讲述睡前故事并获得编码建议。免费 ChatGPT 用户将可以与新的 GPT-4o 模型进行有限次数的交互，然后该工具会自动恢复依赖旧的 GPT-3.5 模型；付费用户将可以使用最新 GPT-4o 访问更多数量的消息。

该模型支持超过 50 种语言，覆盖超过 97%的口语语言。它目前是 LMSYS Elo Arena 基准测试中的领先模型。

大语言模型 GPT-4o 是一个针对 GPT-4 的升级版，该模型更加擅长处理文字和音频，而且在速度、成本效益及多模态交互等方面都有了极大的提升。此外，该模型面向所有用户，而不是局限于付费群体。