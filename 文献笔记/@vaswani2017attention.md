---
aliases:
  - Transformer
tags:
  - CCF/A/NeurIPS
year: 2017
title: Attention is all you need
container: Adv. Neural Inf. Process. Syst.
url: 
zotero: zotero://select/items/@vaswani2017attention
authors:
  - "[[Ashish Vaswani]]"
  - "[[Noam Shazeer]]"
  - "[[Niki Parmar]]"
  - "[[Jakob Uszkoreit]]"
  - "[[Llion Jones]]"
  - "[[Aidan N Gomez]]"
  - "[[Łukasz Kaiser]]"
  - "[[Illia Polosukhin]]"
github: https://github.com/hyunwoongko/transformer
---
- [ ] 《Attention is all you need》[🆉](zotero://select/items/@vaswani2017attention) ^read

related:: [[ChatGPT]], [[AI]]
affiliation:: 

---

- abbr.

#### comment

## 0 abstract

## 1 Intro


## 2 Background

普通黏贴：

“Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.” (Vaswani et al., 2017, p. 2) ^sample-raw


Text Format 自定义黏贴结果：

Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. [🔖](zotero://open-pdf/library/items/NI67YQF6?page=2&annotation=WUFVWDU8) ^sample-format
